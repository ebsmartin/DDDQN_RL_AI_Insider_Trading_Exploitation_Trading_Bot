import pandas as pd
import os
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

class DataManager:
    def __init__(self):
        # Dictionary to store the key:ACCESSION_NUMBER value: [normalized_df, reference df]
        self.data_dict = {}
        self.train_data_dict = {}
        self.test_data_dict = {}

    def prepare_data(self, directory):
        all_data_df = pd.DataFrame()
        # for all csvs in the directory that contain 2021
        for filename in os.listdir(directory):
            if filename.endswith(".csv"):
                print(filename)
                # Read in the csv
                df = pd.read_csv(directory + filename)
                # Append to the final dataframe
                all_data_df = all_data_df.append(df)
        
        # ensure dates are in datetime format
        # timestamp is 9/1/2022  10:00:00 AM, FILING_DATE is 2022-09-01
        all_data_df['FILING_DATE'] = pd.to_datetime(all_data_df['FILING_DATE'], format='%m/%d/%Y')
        all_data_df['timestamp'] = pd.to_datetime(all_data_df['timestamp'], format='%m/%d/%Y %H:%M')
        # ensure close is a float
        all_data_df['close'] = all_data_df['close'].astype(float)
        # ensure ACCESSION_NUMBER is a string
        all_data_df['ACCESSION_NUMBER'] = all_data_df['ACCESSION_NUMBER'].astype(str)
        # ensure ISSUERTRADINGSYMBOL is a string
        all_data_df['ISSUERTRADINGSYMBOL'] = all_data_df['ISSUERTRADINGSYMBOL'].astype(str)
        # count the number of rows with NaN values
        # print(all_data_df.isnull().sum())
        # drop the rows with NaN values
        all_data_df = all_data_df.dropna(axis=0, how='any')


        # Group the DataFrame by the 'ACCESSION_NUMBER' column
        groups = all_data_df.groupby('ACCESSION_NUMBER')
        # Iterate over the groups
        for accession_number, dataframe in groups:
            # 'name' is the unique value of 'ACCESSION_NUMBER' for this group
            # 'group' is a DataFrame containing only the rows with this 'ACCESSION_NUMBER'
            # Create non_normalized_data_df
            reference_data_group = self.create_reference_data(dataframe)
            # Normalize the group
            normalized_data_group = self.normalize_data(dataframe)
            # Add the group and the normalized group to the dictionary
            self.data_dict[accession_number] = [normalized_data_group, reference_data_group]

        self.split_data()


    def normalize_data(self, data):
        # Drop the non-numeric columns
        data = data.drop(columns=['ACCESSION_NUMBER', 'FILING_DATE', 'PERIOD_OF_REPORT', 'ISSUERTRADINGSYMBOL', 
                                'ND_T_TRANS_DATE', 'D_T_TRANS_DATE', 'timestamp', 'close'])
        # Normalize the data
        normalized_data_df = pd.DataFrame(MinMaxScaler().fit_transform(data), columns=data.columns)
        return normalized_data_df


    def create_reference_data(self, data):
        reference_data_df = data[['ACCESSION_NUMBER', 'FILING_DATE', 'ISSUERTRADINGSYMBOL', 'timestamp', 'close']]
        return reference_data_df
    
    def split_data(self, test_size=0.25):
        # Get the keys of the data_dict
        keys = list(self.data_dict.keys())
        # Split the keys into a training set and a test set
        train_keys, test_keys = train_test_split(keys, test_size=test_size)
        # Create the train_data_dict and test_data_dict
        self.train_data_dict = {key: self.data_dict[key] for key in train_keys}
        self.test_data_dict = {key: self.data_dict[key] for key in test_keys}
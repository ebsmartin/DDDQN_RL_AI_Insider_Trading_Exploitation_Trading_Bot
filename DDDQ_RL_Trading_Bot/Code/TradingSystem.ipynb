{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, get_rank, get_world_size, destroy_process_group\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import classes\n",
    "from Agent import Agent\n",
    "from DataVisualizer import DataVisualizer\n",
    "from DataManager import DataManager\n",
    "from NumpyEncoder import NumpyEncoder\n",
    "\n",
    "# set Rank environment variables\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "\n",
    "def setup_distributed(local_rank):\n",
    "    # Set environment variables\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "    os.environ['WORLD_SIZE'] = '1'\n",
    "    os.environ['RANK'] = '0'\n",
    "\n",
    "    # Initialize the process group\n",
    "    if not dist.is_initialized():\n",
    "        dist.init_process_group(backend='gloo', init_method='env://')\n",
    "    torch.cuda.set_device(local_rank)\n",
    "\n",
    "    return local_rank\n",
    "\n",
    "\n",
    "class TradingSystem:\n",
    "    def __init__(self, initial_investment=10000, local_rank=0):\n",
    "        self.local_rank = local_rank\n",
    "        self.INITIAL_INVESTMENT = initial_investment\n",
    "        self.NUM_EPISODES = None\n",
    "        self.trading_agent = None\n",
    "        self.data_manager = DataManager()\n",
    "        self.train_df_shape = None\n",
    "        self.test_df_shape = None\n",
    "        self.data_visualizer = None\n",
    "        self.running_profit = []\n",
    "\n",
    "    def load_and_prepare_data(self, directory):\n",
    "        # create the test and train df dictionaries for each csv file in the directory\n",
    "        self.data_manager.prepare_data(directory)\n",
    "        self.NUM_EPISODES = len(self.data_manager.train_data_dict)\n",
    "\n",
    "    def manual_data_partition(self, data):\n",
    "        total_size = len(data)\n",
    "        per_gpu = total_size // dist.get_world_size()\n",
    "        start = self.local_rank * per_gpu\n",
    "        end = start + per_gpu if self.local_rank < dist.get_world_size() - 1 else total_size\n",
    "        return data[start:end]\n",
    "\n",
    "    def setup_trading_agent(self):\n",
    "        self.trading_agent = Agent(self.train_df_shape, self.NUM_EPISODES) \n",
    "        if os.path.exists(\"Output/online_model/model.pt\"):\n",
    "            print(\"Loading the model\")\n",
    "            self.trading_agent.load_model()\n",
    "        else:\n",
    "            print(\"No model found, training from scratch\")\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.trading_agent.model = self.trading_agent.model.cuda(self.local_rank)\n",
    "        self.trading_agent.model = DDP(self.trading_agent.model, device_ids=[self.local_rank])\n",
    "        \n",
    "    # Curriculum 1 \n",
    "    def train(self):\n",
    "        episode_mem = [{\"Actions\": [], \"Inventory Size\": [], \"Portfolio Value\": [], \"Realized Profit\": [], \"Reward\": [], \"Done\": [], \"Epsilon\": [], \"MSE Loss\": []} for _ in range(self.NUM_EPISODES)]\n",
    "        t0 = time()\n",
    "        episode_num = 0\n",
    "        for accession_number, data in self.data_manager.train_data_dict.items():\n",
    "            normalized_df, reference_df = data\n",
    "            self.train_df_shape = normalized_df.shape\n",
    "            print(f'train_df_shape {self.train_df_shape}')\n",
    "            self.trading_agent = Agent(self.train_df_shape, self.NUM_EPISODES)\n",
    "            print(f\"\\n===== Episode {episode_num + 1} : {accession_number} =====\")\n",
    "            self.trading_agent.inventory = []\n",
    "            state = self.trading_agent.get_state(0, normalized_df)\n",
    "            balance = self.INITIAL_INVESTMENT\n",
    "            portfolio_value = 0\n",
    "            self.trading_agent.portfolio = [0, self.INITIAL_INVESTMENT, portfolio_value]\n",
    "            done = False\n",
    "            print(len(normalized_df))\n",
    "            for t in range(len(normalized_df) - 1):\n",
    "                if done:\n",
    "                    break\n",
    "                action = self.trading_agent.get_action(state, t, reference_df)\n",
    "                next_state = self.trading_agent.get_state(t + 1, normalized_df)\n",
    "                reward = self.trading_agent.trade(t, action, normalized_df, reference_df, self.INITIAL_INVESTMENT, len(normalized_df)-1, trading_fee_rate=0.01)\n",
    "                if action == 0:  # sell\n",
    "                    balance += reference_df[\"close\"].iloc[t]\n",
    "                elif action == 2 and balance >= reference_df[\"close\"].iloc[t]:  # buy\n",
    "                    balance -= reference_df[\"close\"].iloc[t]\n",
    "                portfolio_value = balance + reference_df[\"close\"].iloc[t] * len(self.trading_agent.inventory) - self.INITIAL_INVESTMENT\n",
    "                done = balance < reference_df[\"close\"].iloc[t] and not self.trading_agent.inventory\n",
    "\n",
    "                self.trading_agent.memory.add_exp(state, action, reward, next_state, done)\n",
    "                loss = self.trading_agent.train() or 0\n",
    "                state = next_state\n",
    "\n",
    "                self.trading_agent.portfolio = [sum(self.trading_agent.inventory), balance, portfolio_value]\n",
    "\n",
    "                episode_mem[episode_num][\"Actions\"].append(int(action))\n",
    "                episode_mem[episode_num][\"Inventory Size\"].append(len(self.trading_agent.inventory))\n",
    "                episode_mem[episode_num][\"Portfolio Value\"].append(portfolio_value)\n",
    "                episode_mem[episode_num][\"Realized Profit\"].append(balance - self.INITIAL_INVESTMENT)\n",
    "                episode_mem[episode_num][\"Reward\"].append(reward)\n",
    "                episode_mem[episode_num][\"Done\"].append(done)\n",
    "                episode_mem[episode_num][\"Epsilon\"].append(self.trading_agent.epsilon)\n",
    "                episode_mem[episode_num][\"MSE Loss\"].append(loss)\n",
    "\n",
    "                if t % 10 == 0:\n",
    "                    print(f\"\"\"\n",
    "                            Time step {t} / {len(normalized_df)}   \n",
    "                            |   Inventory Size: {len(self.trading_agent.inventory)}\n",
    "                            |   Action: {int(action)}\n",
    "                            |   Portfolio Value: {round(episode_mem[episode_num]['Portfolio Value'][t], 3)} \n",
    "                            |   Realized Profit: {round(episode_mem[episode_num]['Realized Profit'][t], 3)}  \n",
    "                            |   Inventory: {len(self.trading_agent.inventory)}   \n",
    "                            |   {reference_df['ISSUERTRADINGSYMBOL'].iloc[t]}: ${round(reference_df['close'].iloc[t], 3)}   \n",
    "                            |   Epsilon: {round(self.trading_agent.epsilon, 4)}   \n",
    "                            |   MSE Loss: {loss}\n",
    "                            \"\"\")\n",
    "            episode_num += 1\n",
    "            realized_profit = balance - self.INITIAL_INVESTMENT\n",
    "            print(f\"Realized Profit: {realized_profit}\")\n",
    "            self.running_profit.append(realized_profit)\n",
    "            self.trading_agent.save_model()\n",
    "\n",
    "        total_sell_actions = sum(episode['Actions'].count(0) for episode in episode_mem)\n",
    "        total_buy_actions = sum(episode['Actions'].count(2) for episode in episode_mem)\n",
    "        total_hold_actions = sum(episode['Actions'].count(1) for episode in episode_mem)\n",
    "        average_reward = np.mean([sum(episode['Reward']) for episode in episode_mem])\n",
    "\n",
    "        with open('Output/training_scores.out', 'a') as f:\n",
    "            f.write(f\"\"\"\n",
    "                    EPISODES Completed {episode_num + 1} |  (runtime: {time() - t0})   \n",
    "                    | Realized Profit: {realized_profit}   |\n",
    "                    Total Sell Actions taken: {total_sell_actions}   |\n",
    "                    Total Buy Actions taken: {total_buy_actions}   |\n",
    "                    Total Hold Actions taken: {total_hold_actions}   |\n",
    "                    Average Reward: {average_reward}   |\n",
    "                    Epsilon is {round(self.trading_agent.epsilon, 3)}   |   \n",
    "                    MSE Loss is {round(episode_mem[episode_num - 1]['MSE Loss'][-1], 3)}\\n\n",
    "                    \"\"\")\n",
    "        with open(\"Output/episode_mem.json\", 'w') as f:\n",
    "            json.dump(episode_mem, f, cls=NumpyEncoder)\n",
    "\n",
    "    def test(self):\n",
    "        testing_mem = {\"Actions\": [], \"Inventory Size\": [], \"Portfolio Value\": [], \"Realized Profit\": [], \n",
    "                        \"Reward\": [], \"Done\": []}\n",
    "        t0 = time()\n",
    "        self.NUM_EPISODES = len(self.data_manager.test_data_dict)\n",
    "        \n",
    "        for accession_number, data in self.data_manager.test_data_dict.items():\n",
    "            normalized_df, reference_df = data\n",
    "            self.test_df_shape = normalized_df.shape\n",
    "            self.trading_agent = Agent(self.test_df_shape, self.NUM_EPISODES)\n",
    "            self.trading_agent.epsilon = 0\n",
    "            self.trading_agent.inventory = []\n",
    "            state = self.trading_agent.get_state(0, normalized_df)\n",
    "            balance = self.INITIAL_INVESTMENT\n",
    "            portfolio_value = 0\n",
    "            self.trading_agent.portfolio = [0, self.INITIAL_INVESTMENT, portfolio_value]\n",
    "\n",
    "            done = False\n",
    "            for t in range(len(normalized_df) - 1):\n",
    "                if done:\n",
    "                    print(\"Done with testing\")\n",
    "                    break\n",
    "                action = self.trading_agent.get_action(state, t, reference_df)\n",
    "                next_state = self.trading_agent.get_state(t + 1, normalized_df)\n",
    "                reward = self.trading_agent.trade(t, action, normalized_df, reference_df, self.INITIAL_INVESTMENT, len(normalized_df)-1, trading_fee_rate=0.01)\n",
    "                if action == 0:  # sell\n",
    "                    balance += reference_df[\"close\"].iloc[t]\n",
    "                elif action == 2 and balance >= reference_df[\"close\"].iloc[t]:  # buy\n",
    "                    balance -= reference_df[\"close\"].iloc[t]\n",
    "                portfolio_value = balance + reference_df[\"close\"].iloc[t] * len(self.trading_agent.inventory) - self.INITIAL_INVESTMENT                \n",
    "                done = balance < reference_df[\"close\"].iloc[t] and not self.trading_agent.inventory\n",
    "                state = next_state\n",
    "                self.trading_agent.portfolio = [sum(self.trading_agent.inventory), balance, portfolio_value]\n",
    "\n",
    "                testing_mem[\"Actions\"].append(int(action))\n",
    "                testing_mem[\"Inventory Size\"].append(len(self.trading_agent.inventory))\n",
    "                testing_mem[\"Portfolio Value\"].append(float(portfolio_value) - self.INITIAL_INVESTMENT)\n",
    "                testing_mem[\"Realized Profit\"].append(float(balance - self.INITIAL_INVESTMENT))\n",
    "                testing_mem[\"Reward\"].append(float(reward))\n",
    "                testing_mem[\"Done\"].append(bool(done))\n",
    "                if t % 1 == 0:\n",
    "                    print(f\"\"\"\n",
    "                            Time step {t} / {len(normalized_df)}   \n",
    "                            |   Inventory Size: {len(self.trading_agent.inventory)}  \n",
    "                            |  Portfolio Value: {round(testing_mem['Portfolio Value'][t], 3)}   \n",
    "                            |  Action: {int(action)}  |  Reward: {round(reward, 3)}\n",
    "                            \"\"\")\n",
    "    \n",
    "        if local_rank == 0:\n",
    "            realized_profit = balance - self.INITIAL_INVESTMENT\n",
    "            print(f\"Realized Profit: {realized_profit}\")\n",
    "            self.running_profit.append(realized_profit)\n",
    "\n",
    "            with open('Output/testing_scores.out', 'a') as f:\n",
    "                f.write(f\"\"\"TESTING (runtime: {time() - t0})   |  \n",
    "                        Portfolio Value is {round(testing_mem['Portfolio Value'][-1], 3)}\\n\n",
    "                        \"\"\")\n",
    "            with open(\"Output/testing_mem.json\", 'w') as f:\n",
    "                json.dump(testing_mem, f, cls=NumpyEncoder)\n",
    "        \n",
    "        elif torch.distributed.is_available() and torch.distributed.is_initialized() and dist.rank == 0:\n",
    "            with open('Output/testing_scores.out', 'a') as f:\n",
    "                f.write(f\"\"\"TESTING (runtime: {time() - t0})   |  \n",
    "                        Portfolio Value is {round(testing_mem['Portfolio Value'][-1], 3)}\\n\n",
    "                        \"\"\")\n",
    "            with open(\"Output/testing_mem.json\", 'w') as f:\n",
    "                json.dump(testing_mem, f, cls=NumpyEncoder)\n",
    "\n",
    "#     def run(self, directory):\n",
    "#         print(\"PyTorch version \" + torch.__version__)\n",
    "#         print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "#         # grab the gpu id if available\n",
    "#         print(\"GPU available: \", torch.cuda.is_available())\n",
    "#         print(\"GPU device: \", torch.cuda.get_device_name(0))\n",
    "#         print(\"GPU device count: \", torch.cuda.device_count())\n",
    "#         print(\"GPU device index: \", torch.cuda.current_device())\n",
    "\n",
    "#         print(torch.cuda.is_available())\n",
    "\n",
    "#         self.local_rank = setup_distributed(self.local_rank)\n",
    "\n",
    "#         self.load_and_prepare_data(directory)\n",
    "#         self.train()\n",
    "#         self.test()\n",
    "\n",
    "#         # Only save models or log information from one process to avoid conflicts\n",
    "#         if dist.get_rank() == 0:\n",
    "#             self.trading_agent.save_model()\n",
    "#             print(\"Model saved\")\n",
    "\n",
    "#         self.data_visualizer = DataVisualizer()\n",
    "#         self.data_visualizer.visualize_data()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize the distributed environment\n",
    "#     local_rank = 0\n",
    "\n",
    "#     # Create a TradingSystem instance\n",
    "#     trading_system = TradingSystem(initial_investment=10000, local_rank=local_rank)\n",
    "\n",
    "#     directory = \"C:\\\\Users\\\\ericb\\\\Desktop\\\\CS 535 - Big Data\\\\Term_Projcet\\\\Storm_ouput\\\\Data_Input\\\\Test\\\\\"\n",
    "#     # Run the trading system\n",
    "#     trading_system.run(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version 1.13.1\n",
      "Num GPUs Available:  1\n",
      "GPU available:  True\n",
      "GPU device:  NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "GPU device count:  1\n",
      "GPU device index:  0\n",
      "True\n",
      "new_storm_output_2015.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '2015-01-29' does not match format '%m/%d/%Y' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m             \u001b[0mdta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz_to_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\_libs\\tslibs\\conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31192\\3775747491.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mtrading_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_rank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msetup_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrading_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mtrading_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_and_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mtrading_system\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31192\\398954800.py\u001b[0m in \u001b[0;36mload_and_prepare_data\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload_and_prepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;31m# create the test and train df dictionaries for each csv file in the directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNUM_EPISODES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_data_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\Desktop\\CS 535 - Big Data\\Term_Projcet\\DDDQN_RL_AI_Insider_Trading_Exploitation_Trading_Bot\\DDDQ_RL_Trading_Bot\\Code\\DataManager.py\u001b[0m in \u001b[0;36mprepare_data\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# ensure dates are in datetime format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# timestamp is 2022-01-04 10:00:00, FILING_DATE is 2022-09-01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mall_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FILING_DATE'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FILING_DATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mall_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y-%m-%d %H:%M:%S'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# ensure close is a float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m    881\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m         \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mcache_dates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# GH#39882 and GH#35888 in case of None and NaT we get duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         res = _to_datetime_with_format(\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_arg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         )\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_to_datetime_with_format\u001b[1;34m(arg, orig_arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    499\u001b[0m         \u001b[1;31m# fallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         res = _array_strptime_with_fallback(\n\u001b[1;32m--> 501\u001b[1;33m             \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    502\u001b[0m         )\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, tz, fmt, exact, errors, infer_datetime_format)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimezones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"%Z\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"%z\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfmt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_return_parsed_timezone_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimezones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ericb\\anaconda3\\envs\\ML_Torch\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data '2015-01-29' does not match format '%m/%d/%Y' (match)"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version \" + torch.__version__)\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())\n",
    "# grab the gpu id if available\n",
    "print(\"GPU available: \", torch.cuda.is_available())\n",
    "print(\"GPU device: \", torch.cuda.get_device_name(0))\n",
    "print(\"GPU device count: \", torch.cuda.device_count())\n",
    "print(\"GPU device index: \", torch.cuda.current_device())\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Initialize the distributed environment\n",
    "local_rank = 0\n",
    "\n",
    "# Create a TradingSystem instance\n",
    "trading_system = TradingSystem(initial_investment=10000, local_rank=local_rank)\n",
    "\n",
    "directory = \"C:\\\\Users\\\\ericb\\\\Desktop\\\\CS 535 - Big Data\\\\Term_Projcet\\\\Storm_ouput\\\\Data_Input\\\\Test\\\\\"\n",
    "# Run the trading system\n",
    "\n",
    "trading_system.local_rank = setup_distributed(trading_system.local_rank)\n",
    "\n",
    "trading_system.load_and_prepare_data(directory)\n",
    "trading_system.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_system.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_system.data_visualizer = DataVisualizer()\n",
    "trading_system.data_visualizer.visualize_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_AI_RL_20230410",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
